p8105_hw2_mx2286
================
Mingye Xie
2024-10-02

### Problem 1

``` r
library(tidyverse)
library(readxl)
trans_ent = 
    read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

``` r
trans_ent |> 
  select(station_name, line) |> 
  distinct()
## # A tibble: 465 × 2
##    station_name             line    
##    <chr>                    <chr>   
##  1 25th St                  4 Avenue
##  2 36th St                  4 Avenue
##  3 45th St                  4 Avenue
##  4 53rd St                  4 Avenue
##  5 59th St                  4 Avenue
##  6 77th St                  4 Avenue
##  7 86th St                  4 Avenue
##  8 95th St                  4 Avenue
##  9 9th St                   4 Avenue
## 10 Atlantic Av-Barclays Ctr 4 Avenue
## # ℹ 455 more rows
```

The next code chunk is similar, but filters according to ADA compliance
as an initial step. This produces a dataframe in which the number of
rows is the number of ADA compliant stations.

``` r
trans_ent |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
## # A tibble: 84 × 2
##    station_name                   line           
##    <chr>                          <chr>          
##  1 Atlantic Av-Barclays Ctr       4 Avenue       
##  2 DeKalb Av                      4 Avenue       
##  3 Pacific St                     4 Avenue       
##  4 Grand Central                  42nd St Shuttle
##  5 34th St                        6 Avenue       
##  6 47-50th Sts Rockefeller Center 6 Avenue       
##  7 Church Av                      6 Avenue       
##  8 21st St                        63rd Street    
##  9 Lexington Av                   63rd Street    
## 10 Roosevelt Island               63rd Street    
## # ℹ 74 more rows
```

``` r
trans_ent |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
## [1] 0.3770492
```

``` r
trans_ent |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
## # A tibble: 60 × 2
##    station_name                  line           
##    <chr>                         <chr>          
##  1 Times Square                  42nd St Shuttle
##  2 125th St                      8 Avenue       
##  3 145th St                      8 Avenue       
##  4 14th St                       8 Avenue       
##  5 168th St - Washington Heights 8 Avenue       
##  6 175th St                      8 Avenue       
##  7 181st St                      8 Avenue       
##  8 190th St                      8 Avenue       
##  9 34th St                       8 Avenue       
## 10 42nd St                       8 Avenue       
## # ℹ 50 more rows

trans_ent |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
## # A tibble: 17 × 2
##    station_name                  line            
##    <chr>                         <chr>           
##  1 14th St                       8 Avenue        
##  2 168th St - Washington Heights 8 Avenue        
##  3 175th St                      8 Avenue        
##  4 34th St                       8 Avenue        
##  5 42nd St                       8 Avenue        
##  6 59th St                       8 Avenue        
##  7 Inwood - 207th St             8 Avenue        
##  8 West 4th St                   8 Avenue        
##  9 World Trade Center            8 Avenue        
## 10 Times Square-42nd St          Broadway        
## 11 59th St-Columbus Circle       Broadway-7th Ave
## 12 Times Square                  Broadway-7th Ave
## 13 8th Av                        Canarsie        
## 14 Franklin Av                   Franklin        
## 15 Euclid Av                     Fulton          
## 16 Franklin Av                   Fulton          
## 17 Howard Beach                  Rockaway
```

### Problem 2

``` r
Mr_Trashwheel = read_excel("202409 Trash Wheel Collection Data.xlsx", sheet = 1, skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(sports_balls = as.integer(round(sports_balls, 0)),
         source = "Mr. Trash Wheel")

Professor_Trashwheel = read_excel("202409 Trash Wheel Collection Data.xlsx", sheet = 2, skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  select(dumpster, month, year, date, weight_tons , volume_cubic_yards,
         plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, homes_powered) |> 
  mutate(year = as.character(year),  # Convert year to character for consistency
         source = "Professor Trash Wheel")
 
Gwynnda_Trashwheel = read_excel("202409 Trash Wheel Collection Data.xlsx", sheet = 4, skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  select(dumpster, month, year, date, weight_tons, volume_cubic_yards,
         plastic_bottles, polystyrene, cigarette_butts, plastic_bags, wrappers, homes_powered) |> 
  mutate(year = as.character(year),  # Convert year to character for consistency
         source = "Gwynnda")
```

``` r
# Combine all datasets into one tidy dataset
Combined_Trashwheel = bind_rows(Mr_Trashwheel, Professor_Trashwheel, Gwynnda_Trashwheel)

glimpse(Combined_Trashwheel)
## Rows: 1,033
## Columns: 17
## $ dumpster           <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, …
## $ month              <chr> "May", "May", "May", "May", "May", "May", "May", "M…
## $ year               <chr> "2014", "2014", "2014", "2014", "2014", "2014", "20…
## $ date               <dttm> 2014-05-16, 2014-05-16, 2014-05-16, 2014-05-17, 20…
## $ weight_tons        <dbl> 4.31, 2.74, 3.45, 3.10, 4.06, 2.71, 1.91, 3.70, 2.5…
## $ volume_cubic_yards <dbl> 18, 13, 15, 15, 18, 13, 8, 16, 14, 18, 15, 19, 15, …
## $ plastic_bottles    <dbl> 1450, 1120, 2450, 2380, 980, 1430, 910, 3580, 2400,…
## $ polystyrene        <dbl> 1820, 1030, 3100, 2730, 870, 2140, 1090, 4310, 2790…
## $ cigarette_butts    <dbl> 126000, 91000, 105000, 100000, 120000, 90000, 56000…
## $ glass_bottles      <dbl> 72, 42, 50, 52, 72, 46, 32, 58, 49, 75, 38, 45, 58,…
## $ plastic_bags       <dbl> 584, 496, 1080, 896, 368, 672, 416, 1552, 984, 448,…
## $ wrappers           <dbl> 1162, 874, 2032, 1971, 753, 1144, 692, 3015, 1988, …
## $ sports_balls       <int> 7, 5, 6, 6, 7, 5, 3, 6, 6, 7, 6, 8, 6, 6, 6, 6, 5, …
## $ homes_powered      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
## $ x15                <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ x16                <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ source             <chr> "Mr. Trash Wheel", "Mr. Trash Wheel", "Mr. Trash Wh…
```

``` r
# Total weight of trash collected by Professor Trash Wheel
total_weight_professor = Combined_Trashwheel |> 
  filter(source == "Professor Trash Wheel") |> 
  summarise(Total_Weight_Tons = sum(weight_tons, na.rm = TRUE))

total_weight_professor
## # A tibble: 1 × 1
##   Total_Weight_Tons
##               <dbl>
## 1              247.
```

``` r
# Total cigarette butts collected by Gwynnda in June 2022
total_cig_butts_gwynnda = Combined_Trashwheel |> 
  filter(source == "Gwynnda", year == "2022", month == "June") |> 
  summarise(Total_Cigarette_Butts = sum(cigarette_butts, na.rm = TRUE))
total_cig_butts_gwynnda
## # A tibble: 1 × 1
##   Total_Cigarette_Butts
##                   <dbl>
## 1                 18120
```

The combined dataset contains 1033 observations from Mr. Trash Wheel,
Professor Trash Wheel, and Gwynnda. Each row represents a specific
dumpster load, with variables capturing important details such as
weight_tons, volume_cubic_yards, plastic_bottles, cigarette_butts, and
homes_powered. From the available data, the total weight of trash
collected by Professor Trash Wheel was 246.74 tons. In June 2022,
Gwynnda collected 18120 cigarette butts.

### Problem 3

``` r
#import data
bakers = read_csv("./bakers.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  separate(baker_name, into = c("first_name", "last_name"), sep = " ") 

bakes = 
  read_csv('./bakes.csv', na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  rename(first_name=baker)

results = 
  read_csv('./results.csv', skip=2, na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  rename(first_name=baker)
```

check and correct tables

``` r
anti_join(bakers, bakes, by = "first_name")
## # A tibble: 23 × 6
##    first_name last_name       series baker_age baker_occupation         hometown
##    <chr>      <chr>            <dbl>     <dbl> <chr>                    <chr>   
##  1 Alice      Fevronia            10        28 Geography teacher        Essex   
##  2 Amelia     LeBruin             10        24 Fashion designer         Halifax 
##  3 Antony     Amourdoux            9        30 Banker                   London  
##  4 Briony     Williams             9        33 Full-time parent         Bristol 
##  5 Dan        Beasley-Harling      9        36 Full-time parent         London  
##  6 Dan        Chambers            10        32 Support worker           Rotherh…
##  7 Helena     Garcia              10        40 Online project manager   Leeds   
##  8 Henry      Bird                10        20 Student                  Durham  
##  9 Imelda     McCarron             9        33 Countryside recreation … County …
## 10 Jamie      Finn                10        20 Part-time waiter         Surrey  
## # ℹ 13 more rows
anti_join(bakers, results, by = "first_name")
## # A tibble: 1 × 6
##   first_name last_name series baker_age baker_occupation hometown    
##   <chr>      <chr>      <dbl>     <dbl> <chr>            <chr>       
## 1 Jo         Wheatley       2        41 Housewife        Ongar, Essex
anti_join(bakes, results, by = c("series", "episode"))
## # A tibble: 0 × 5
## # ℹ 5 variables: series <dbl>, episode <dbl>, first_name <chr>,
## #   signature_bake <chr>, show_stopper <chr>

bakers|>
  mutate(first_name = ifelse(first_name == "Jo","Joanne", first_name))
## # A tibble: 120 × 6
##    first_name last_name   series baker_age baker_occupation             hometown
##    <chr>      <chr>        <dbl>     <dbl> <chr>                        <chr>   
##  1 Ali        Imdad            4        25 Charity worker               Saltley…
##  2 Alice      Fevronia        10        28 Geography teacher            Essex   
##  3 Alvin      Magallanes       6        37 Nurse                        Brackne…
##  4 Amelia     LeBruin         10        24 Fashion designer             Halifax 
##  5 Andrew     Smyth            7        25 Aerospace engineer           Derby /…
##  6 Annetha    Mills            1        30 Midwife                      Essex   
##  7 Antony     Amourdoux        9        30 Banker                       London  
##  8 Beca       Lyne-Pirkis      4        31 Military Wives' Choir Singer Aldersh…
##  9 Ben        Frazer           2        31 Graphic Designer             Northam…
## 10 Benjamina  Ebuehi           7        23 Teaching assistant           South L…
## # ℹ 110 more rows
```

merge data

``` r
bakes_total = 
  left_join(bakers, results, by = c("first_name","series")) |> 
  left_join(bakes, by = c("first_name", "series", "episode")) |> 
  relocate(series,episode,first_name,last_name, signature_bake,show_stopper,technical,result,baker_age, baker_occupation, hometown) |> 
  arrange(series, episode)
```

export

``` r
write_csv(bakes_total, 'data/bakes_tatal.csv')
```

Data Cleaning Process: I imported and cleaned three datasets
(bakers.csv, bakes.csv, and results.csv), handling missing values and
standardizing column names with janitor::clean_names(). In bakers.csv, I
split baker_name into first_name and last_name to align with the other
datasets, where I renamed the baker column to first_name. To check for
inconsistencies, I used anti_join() and found that Joanne was recorded
as “Jo” in some datasets, which I corrected. Additionally, I found that
Series 9 and 10 data was missing from bakes.csv. After fixing these
issues, I merged the datasets using left_join() on first_name, series,
and episode, rearranged the columns, and sorted the data by series and
episode. The final dataset was exported as bakes_total.csv.

Summary of the Final Dataset: The final dataset contains information for
Series 1 to 8, with key variables like baker_age, baker_occupation,
signature_bake, show_stopper, technical, and results. It includes r
ncol(bakes_total) variables and r nrow(bakes_total) observations.

Issues Identified: Name inconsistency: Corrected “Jo” to “Joanne”.
Missing data: Series 9 and 10 data were absent from bakes.csv.

``` r
bakes_stars =
  bakes_total |>
  filter(series %in% c(5,6,7,8,9,10), result %in% c("STAR BAKER", "WINNER"))
```

In many seasons, the final winner was predictable, such as Richard Burr
(Season 5) and Nadiya Hussain (Season 6), who were named “Star Baker”
multiple times, while in contrast, David Atherton (Season 10) was a
surprise winner, as he did not win any “Star Baker” titles before the
final.

``` r
viewers = 
  read_csv('./viewers.csv', na = c("NA", ".", "")) |>
  janitor::clean_names() |> 
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewer"
  ) |> 
   mutate(series = readr::parse_number(series)) |>
  relocate(series) |>
  arrange(series, episode)

head(viewers, 10)
## # A tibble: 10 × 3
##    series episode viewer
##     <dbl>   <dbl>  <dbl>
##  1      1       1   2.24
##  2      1       2   3   
##  3      1       3   3   
##  4      1       4   2.6 
##  5      1       5   3.03
##  6      1       6   2.75
##  7      1       7  NA   
##  8      1       8  NA   
##  9      1       9  NA   
## 10      1      10  NA

viewers |> 
  filter(series == 1) |> 
  summarise(mean(viewer, na.rm = TRUE))
## # A tibble: 1 × 1
##   `mean(viewer, na.rm = TRUE)`
##                          <dbl>
## 1                         2.77

viewers |> 
  filter(series == 5) |> 
  summarise(mean(viewer, na.rm = TRUE))
## # A tibble: 1 × 1
##   `mean(viewer, na.rm = TRUE)`
##                          <dbl>
## 1                         10.0
```

The average viewship in season 1 is 2.77 and season 5 is 10.0.
